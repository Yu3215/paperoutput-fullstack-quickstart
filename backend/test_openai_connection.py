#!/usr/bin/env python3
"""
æµ‹è¯•OpenAI APIè¿æ¥çš„è„šæœ¬
"""

import os
import sys
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

def test_openai_connection():
    """æµ‹è¯•OpenAI APIè¿æ¥"""
    load_dotenv()
    
    # è·å–ç¯å¢ƒå˜é‡
    api_key = os.getenv("OPENAI_API_KEY")
    api_base = os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
    
    if not api_key:
        print("âŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„ OpenAI API Key")
        return False
    
    print(f"ğŸ”§ é…ç½®ä¿¡æ¯:")
    print(f"   API Key: {api_key[:8]}...{api_key[-4:]}")
    print(f"   API Base: {api_base}")
    print()
    
    try:
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
        llm = ChatOpenAI(
            model="deepseek-r1:70b",
            temperature=0,
            max_retries=1,
            api_key=api_key,
            base_url=api_base,
        )
        
        print("ğŸ”„ æ­£åœ¨æµ‹è¯•APIè¿æ¥...")
        
        # å‘é€æµ‹è¯•è¯·æ±‚
        response = llm.invoke("è¯·å›å¤'è¿æ¥æˆåŠŸ'")
        
        print("âœ… è¿æ¥æˆåŠŸ!")
        print(f"   æ¨¡å‹å“åº”: {response.content}")
        return True
        
    except Exception as e:
        print("âŒ è¿æ¥å¤±è´¥!")
        print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
        print()
        print("ğŸ” å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("   1. æ£€æŸ¥ OPENAI_API_KEY æ˜¯å¦æ­£ç¡®")
        print("   2. æ£€æŸ¥ OPENAI_API_BASE æ˜¯å¦æ­£ç¡®")
        print("   3. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   4. æ£€æŸ¥APIé…é¢æ˜¯å¦å……è¶³")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ OpenAI API è¿æ¥æµ‹è¯•")
    print("=" * 50)
    
    success = test_openai_connection()
    
    print("=" * 50)
    if success:
        print("ğŸ‰ æµ‹è¯•é€šè¿‡! æ‚¨å¯ä»¥å¼€å§‹ä½¿ç”¨è®ºæ–‡Frameworkç”Ÿæˆå™¨äº†ã€‚")
        sys.exit(0)
    else:
        print("ğŸ’¥ æµ‹è¯•å¤±è´¥! è¯·æ£€æŸ¥é…ç½®åé‡è¯•ã€‚")
        sys.exit(1)

if __name__ == "__main__":
    main() 